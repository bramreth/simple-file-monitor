"""
this is an interesting problem listening to stuff the two real approaches in my eyes.

Either use a chron job or listen to signals when there are updates. This would be
very OS dependant, but not being wasteful is too much benefit to avoid. I'm currently working on
a windows machine with a linux terminal, I believe I should be able to use linux inotify libs
to track file updates, so let's get that working. a simple constructor that listens to a subdir

https://pypi.org/project/watchdog/
for posting to the server
https://pypi.org/project/requests/
watchdog docs
"""

from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import sys
import time
import logging
import requests
import hashlib
import json

path = ""


# inherit the filesystem event handler and add functionality
class CustomWatcher(FileSystemEventHandler):
    # once the server is deployed, this would obviously need to be parmeterised
    url = 'http://127.0.0.1:8080'

    def on_moved(self, event):
        super(CustomWatcher, self).on_moved(event)
        logging.info(event)

        src_file = event.src_path.lstrip(path)
        dest_file = event.dest_path.lstrip(path)
        json_dat = json.dumps({"src": src_file, "dest": dest_file})

        requests.post(self.url + "/move", data=json_dat)

    def on_created(self, event):
        super(CustomWatcher, self).on_created(event)
        logging.info(event)

        file = event.src_path.lstrip(path)

        # the server needs to know if it's a file or directory to decide whether to use mkdir or touch
        if event.is_directory:
            requests.post(self.url + "/create_dir", data=file)
        else:
            requests.post(self.url + "/create_file", data=file)
            # if we have created a file it may have contents we want to upload.
            # so let's propogate a modified event manually
            self.on_modified(event)

    def on_deleted(self, event):
        super(CustomWatcher, self).on_deleted(event)
        logging.info(event)
        file = event.src_path.lstrip(path)
        requests.post(self.url + "/delete", data=file)

    def on_modified(self, event):
        super(CustomWatcher, self).on_modified(event)
        logging.info(event)
        if event.is_directory:
            # modified events for directories are meaningless to us
            return
        file = event.src_path.lstrip(path)
        # boilerplate code to generate the hash for our file
        file_hash = hashlib.md5()
        with open(event.src_path, 'rb') as payload:
            for chunk in iter(lambda: payload.read(4096), b""):
                file_hash.update(chunk)
            file_hash = file_hash.hexdigest()
        # modify request returns 200 if the server has a different hash to us, indicating we should then
        # post the file
        response = requests.get(self.url + "/modify_request", params={"file": file, "hash": file_hash})
        if response.status_code == 200:
            # post the media
            with open(event.src_path, 'r') as payload:
                # as I am using the simplest http server possible bytestreaming files isn't straightforward,
                # so I opted for a naive string upload of the file contents as the payload get's verified via the
                # hash anyway and I didn't want to waste too much time on fluff.
                dat = json.dumps({"filename": file, "contents": payload.read()})
                # I would like to expand this by having a key be generated by the server so we don't need to reupload
                # the filename in the post, this would be necessary for security reasons and for keeping better track
                # of ongoing connections.
                # this would also let us ignore posts that had not previously established a session with the server.
                r = requests.post(self.url + "/modify", data=dat)
        else:
            logging.warning("server file copy already up to date.")


# code from the watchdog library docs
def setup_watchdog():
    logging.basicConfig(level=logging.INFO,
                        format='%(asctime)s - %(message)s',
                        datefmt='%Y-%m-%d %H:%M:%S')
    # this watches a file at a sys argument path
    event_handler = CustomWatcher()
    observer = Observer()
    # this will setup a watcher with our custom event handler perpetually
    observer.schedule(event_handler, path, recursive=True)
    observer.start()
    try:
        # this feels greedy
        while True:
            time.sleep(1)
    finally:
        observer.stop()
        observer.join()


if __name__ == "__main__":
    # this should be updated to use argparse
    path = sys.argv[1] if len(sys.argv) > 1 else '.'
    setup_watchdog()